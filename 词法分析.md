## 词法分析

词法分析的本质是对源文件进行扫描，并将扫描到的关键字封装成Token对象，所谓 **token** ，就是源文件中不可再进一步分割的一串字符。比如 for 关键字，常量，操作符，这里可以采用最简单的数据类型 (token_type,value) 来保存Token，比如：

```sh
(T_for, for)
(T_constant, 100)
(T_add, +)
```

在 main.py 中调用 lexer() 函数完成词法分析。主要功能由 Lexer 类完成，对源文件进行逐字扫描，将匹配到的关键字分成不同的类。在 Lexer.lexer() 方法中对要扫描的字符做如下分类：

```python
while word_num < len(source_stream):
    # 判断是否为注释或者不需要分析的词法,比如\n,\t
	word_num = self.If_skip_word(word_num)
	# 是否为引入头文件
	if source_stream[word_num] == "#":
		pass
	# 是下划线或者字母
	elif source_stream[word_num] == "_" or source_stream[word_num].isalpha():
		pass
	# 是数字
	elif source_stream[word_num].isdigit():
		pass
	# 是运算符
	elif source_stream[word_num] in operatorList:
		pass
	# 是特殊符号
	elif source_stream[word_num] in specialChar:
		pass
```

根据匹配到的关键词，将其封装成各种Token，Token 类的数据结构：

```python
class Token(object):
	'''Token分类'''
	def __init__(self,type_key,value):
		self.value = value
		self.value = type_key
```

而可供分配的Token 类分为两个大类，一类是由关键字和操作符组成的固定Token：

```python
# 关键字,操作符 Token
keyWords_Token = {
	'int':'T_int',
	'double':'T_double',
	'float':'T_float',
	'char':'T_char',
	'void':'T_void',
	'for':'T_for',
	'while':'T_while',
	'if':'T_if',
	'else':'T_else',
	'do':'T_do',
	'return':'T_return',
	'include':'T_include',
	'+':'T_add',
	'-':'T_sub',
	'*':'T_mul',
	'/':'T_div',
	'=':'T_assign',
	'&':'T_and',
	'|':'T_or',
	'>':'T_gt',
	'<':'T_lt',
	'>=':'T_ge',
	'<=':'T_le',
	'++':'T_addadd',
	'--':'T_subsub',
	'!=':'T_notequal',
	'==':'T_equal',
    '+=':'T_add_assign',
	'-=':'T_sub_assign',
	'*=':'T_mul_assign',
	'/=':'T_div_assign',
	'#':'T_sharp',
	'(':'T_l1_bracket',
	')':'T_r1_bracket',
	'[':'T_l2_bracket',
	']':'T_r2_bracket',
	'{':'T_l3_braket',
	'}':'T_r3_braket',
	',':'T_comma',
	';':'T_semicolon',
	'\"':'T_quote'
}
```

另一类是不固定的Token，用来保存变量名的标识符，常数以及字符串：

```python
# 其他Token
other_Token = {
	'identifier':'T_identifier',#标识符
	'constant':'T_constant',#常数
	'string':'T_string',#字符串
}
```

## 案例

简单C程序 test.c

```c
#include<stdio.h>

/* 你好 */

int main(){
	int i,j;
	int sum=0;
	for(i=0;i<=100;i++){
		sum = sum + i;
	}
	printf("sum = %d\n",sum);
	if (sum >= 4950){
		printf("sum >= 4950\n");
	}
	return 0;
}
```

生成的 Token 序列：

```sh
(T_sharp, #)
(T_include, include)
(T_lt, <)
(T_identifier, stdio.h)
(T_gt, >)
(T_int, int)
(T_identifier, main)
(T_l1_bracket, ()
(T_r1_bracket, ))
(T_l3_braket, {)
(T_int, int)
(T_identifier, i)
(T_comma, ,)
(T_identifier, j)
(T_semicolon, ;)
(T_int, int)
(T_identifier, sum)
(T_assign, =)
(T_constant, 0)
(T_semicolon, ;)
(T_for, for)
(T_l1_bracket, ()
(T_identifier, i)
(T_assign, =)
(T_constant, 0)
(T_semicolon, ;)
(T_identifier, i)
(T_le, <=)
(T_constant, 100)
(T_semicolon, ;)
(T_identifier, i)
(T_addadd, ++)
(T_r1_bracket, ))
(T_l3_braket, {)
(T_identifier, sum)
(T_assign, =)
(T_identifier, sum)
(T_add, +)
(T_identifier, i)
(T_semicolon, ;)
(T_r3_braket, })
(T_identifier, printf)
(T_l1_bracket, ()
(T_quote, ")
(T_string, sum = %d\n)
(T_quote, ")
(T_comma, ,)
(T_identifier, sum)
(T_r1_bracket, ))
(T_semicolon, ;)
(T_if, if)
(T_l1_bracket, ()
(T_identifier, sum)
(T_ge, >=)
(T_constant, 4950)
(T_r1_bracket, ))
(T_l3_braket, {)
(T_identifier, printf)
(T_l1_bracket, ()
(T_quote, ")
(T_string, sum >= 4950\n)
(T_quote, ")
(T_r1_bracket, ))
(T_semicolon, ;)
(T_r3_braket, })
(T_return, return)
(T_constant, 0)
(T_semicolon, ;)
(T_r3_braket, })
```

